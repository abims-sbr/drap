[SCHEDULER]
type = local    # This value can be 'local' or 'sge'
# The sge version doesn't work on our infrastructure. It is a work in progress.
local_cpu = 6 # The number of available cpu for local scheduler (Not used if type = sge)

[SOFTWARES] # Softwares called by the workflow - in order to change version, please edit the [PATH] or/and [ENV] parts below
bedtools                          # >=2.22.1
blastn                            # ncbi-blast>=2.2.29+
bl2seq                            # ncbi-blast>=2.2.29+
blat                              # >=35
bwa                               # >=0.7.15
cd-hit                            # >=4.6
cd-hit-est                        # >=4.6
cutadapt                          # >=1.8.3
dc                                # >=1.3.95 (in bc >=1.06.95)
exonerate                         # >= 2.2.0
express                           # >= 1.5.1
fastq_illumina_filter             # >= 0.1
generate_plot.py                  # BUSCO >=3.0 package
getorf                            # EMBOSS >=6.4.0.0
insilico_read_normalization.pl    # Trinity package >?2.4.0
interleave-reads.py               # Khmer package >=2.0
normalize-by-median.py            # Khmer package >=2.0
oases                             # >=0.2.06
parallel                          # >=20141022
perl                              # >=5
python                            # =2.7.x
rsync                             # >=3.0.6
run_BUSCO.py                      # >=3.0
samtools                          # >=1.3.1
seqclean
split-paired-reads.py             # Khmer package >=2.0
STAR                              # >=2.4.0i
tgicl                             # >=2.1
TransDecoder.LongOrfs             # >=2.0.1
TransDecoder.Predict              # >=2.0.1
transrate                         # >= 1.0.1
trim_galore                       # >= 0.4.0
Trinity                           # >?2.4.0
vecscreen                         # ncbi_cxx >=12_0_0
velveth
velvetg

[PATH] # Folders added to the PATH
/opt/6.x/parallel/bin                            # parallel 20170622
/usr/local/genome2/ncbi_cxx--12_0_0/bin          # vecscreen
/usr/local/genome2/ncbi-blast-2.2.30+/bin/       # blast 2.2.30+
/usr/local/genome2/busco-3.0.1                   # BUSCO 3.0.1
/usr/local/genome2/trinityrnaseq-2.4.0           # Trinity 2.4.0
/usr/local/genome2/trinityrnaseq-2.4.0/util/     # insilico_read_normalization.pl
/usr/local/genome2/transrate-1.0.3/              # transrate 1.0.3
/usr/local/genome2/khmer_venv_2.0/bin/           # khmer 2.0

[ENV] # Commands to execute to set the environnement (i.e. module load)
# /!\ importing conda environments is not possible. DRAP will produce csh scripts and csh is not supported now by conda.
# /!\ when using python virtualenv, please do not forget to source 'activate.csh' instead of 'activate'
# /!\ if you have multiple environment to source, separate the commands with a ';'
preprocess_env = source /usr/local/genome2/envs/java-1.8-activate.csh; source /usr/local/genome2/khmer_venv_2.0/bin/activate.csh # khmer 2.0 & Trinity
dbg_env = source /usr/local/genome2/envs/java-1.8-activate.csh # Trinity

[DATABASE] # External data sources
# Data available at:
# ftp://ftp.ncbi.nlm.nih.gov/pub/kitts/adaptors_for_screening_euks.fa
# ftp://ftp.ncbi.nlm.nih.gov/pub/kitts/contam_in_euks.fa.gz
# ftp://ftp.ncbi.nlm.nih.gov/pub/kitts/rrna.gz
# ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/mito.nt.gz
# index fasta files with: makeblastdb -in <fasta> -dbtype nucl
adaptors_for_screening_euks = /db/kitts/current/blast/adaptors_for_screening_euks.fa
contam_in_euks = /db/kitts/current/blast/contam_in_euks.fa
mito = /db/mito.nt/current/blast/mito.nt
rrna = /db/kitts/current/blast/rrna

[SOFTWARE CONFIGURATION] # options of softwares called by the workflow
n_cpu = 6 # maximum number of CPU cores used by one software in the workflow
oases_ram = 100
#trinity_grid_module = GenotoulGridRunner
busco_lineage_directory = /db/off_biomaj/busco/v2/eukaryota_odb9
star_genome_generate_ram = 64
star_genome_generate_cpu = $n_cpu
star_genome_sa_index = 14
runAssessment_ram = 100

[SGE CONFIGURATION] # configuration SGE
pe_smp = thread  # parallel environment - get the list with qconf -sql
default_queue = long.q@@bigcpu
mem_queue = bigmem.q@@bigmem
node_max_mem = 240

[SGE RESOURCES] # resources requested for workflow specific task or step
preprocess_res = -R y -pe $pe_smp $n_cpu # resources requested in --no-norm mode
normalize_res = -R y -pe $pe_smp $n_cpu -l mem_free=%MEM%G,h_vmem=%H_VMEM%G
oases_res = -R y -l mem_free=%MEM%G,h_vmem=%H_VMEM%G
trinity_1_res = -R y -pe $pe_smp $n_cpu -l mem_free=%MEM%G,h_vmem=%H_VMEM%G
trinity_2_res = -R y -l mem_free=4G,h_vmem=8G
clustering_res = -R y -pe $pe_smp $n_cpu -l mem_free=8G,h_vmem=16G
asm_res = -R y -pe $pe_smp $n_cpu
rmbt_editing_res = -R y -pe $pe_smp $n_cpu -l mem_free=8G,h_vmem=16G
postprocess_res = -R y -pe $pe_smp $n_cpu -l mem_free=16G,h_vmem=24G
meta_cluster_orf_res = -R y -pe $pe_smp $n_cpu
meta_cluster_contig_res = -R y -pe $pe_smp $n_cpu
meta_index_res = -R y -pe $pe_smp $n_cpu
meta_filter_res = -R y -l mem_free=16G,h_vmem=32G
meta_postprocess_res = -R y -pe $pe_smp $n_cpu -l mem_free=16G,h_vmem=24G
samtools_idx_res = -R y -l mem_free=16G,h_vmem=32G
bwa_map_res = -l mem_free=8G,h_vmem=16G
star_idx_res = -R y -pe $pe_smp $n_cpu -l mem_free=8G,h_vmem=8G
star_map_res = -l mem_free=8G,h_vmem=16G
